<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>maskrcnn-benchmark转onnx再转TensorRT实录 | 金天的个人博客</title>
    <meta property="og:title" content="maskrcnn-benchmark转onnx再转TensorRT实录 - 金天的个人博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2019-09-26T10:29:37&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2019-09-26T10:29:37&#43;08:00'>
        
    <meta name="Keywords" content="golang,go语言,go语言笔记,金天,人工智能,java,android,博客,项目管理,python,软件架构,公众号,小程序,AI项目管理">
    <meta name="description" content="maskrcnn-benchmark转onnx再转TensorRT实录">
        
    <meta name="author" content="金天">
    <meta property="og:url" content="https://jintian93.github.io/post/2019_09_26_10_maskrcnn-benchmark%E8%BD%AConnx%E5%86%8D%E8%BD%ACTensorRT%E5%AE%9E%E5%BD%95/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "238864368",
        enable_page_level_ads: true
    });
    </script>
    


    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://jintian93.github.io">
                        金天的个人博客
                    </a>
                
                <p class="description">专注于AI算法研发与落地应用，无人驾驶，模型压缩与加速，边缘端侧推理，AI项目管理与核心技术输出，腾讯自动驾驶专家</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://jintian93.github.io">首页</a>
                    
                    <a  href="https://jintian93.github.io/tools/" title="工具">工具</a>
                    
                    <a  href="https://jintian93.github.io/archives/" title="归档">归档</a>
                    
                    <a  href="https://jintian93.github.io/about/" title="关于">关于</a>
                    
                    <a  href="https://jintian93.github.io/about/" title="关于我">关于我</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#mmdetectiononnxtensorrt">mmdetection导入onnx转TensorRT</a></li>
    <li><a href="#heading">总结</a></li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">maskrcnn-benchmark转onnx再转TensorRT实录</h1>
        </header>
        <date class="post-meta meta-date">
            2019年9月26日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <p>本文介绍 maskrcnn-benchmark转onnx再转TensorRT实录</p>
<!-- raw HTML omitted -->
<h1 id="maskrcnn-benchmarkonnxtensorrt">maskrcnn-benchmark转onnx再转TensorRT实录</h1>
<blockquote>
<p>This article was original written by Jin Tian, welcome re-post, first come with <a href="https://jinfagang.github.io">https://jinfagang.github.io</a> . but please keep this copyright info, thanks, any question could be asked via wechat: <code>jintianiloveu</code></p>
</blockquote>
<p>这篇文章将记录一下，如何通过onnx将maskrcnn模型转到tensorrt。到目前位置，我们基本上可以转到onnx，并通过onnxruntime得到正确的推理结果。但唯一不好的地方在于，无法转到tensorrt，问题主要在于：</p>
<ol>
<li>onnx为dynamic input的尺寸，这在TensorRT里面是无法支持的；</li>
<li>当你将输入尺寸固定之后，输出尺寸也随之固定了，这种情况下模型基本上无法推理。</li>
</ol>
<p>针对这么一种情况，解决方案不是没有，但！</p>
<p>当我升级到TensorRT6.0和onnx-tensorrt对应的6.1的时候，惊奇的发现，dynamic的输入也是被支持的！！那么这个时候情况就变了哇！！我们接下来就从TensorRT6.0开始踩一踩坑！</p>
<ol>
<li>
<p>遇到的第一个错误是这个：</p>
<pre><code>While parsing node number 404 [Cast -&gt; &quot;407&quot;]:
--- Begin node ---
input: &quot;406&quot;
output: &quot;407&quot;
name: &quot;406&quot;
op_type: &quot;Cast&quot;
attribute {
  name: &quot;to&quot;
  i: 1
  type: INT
}
   
--- End node ---
ERROR: onnx-tensorrt/builtin_op_importers.cpp:317 In function importCast:
[8] Assertion failed: trt_dtype == nvinfer1::DataType::kHALF &amp;&amp; cast_dtype == ::ONNX_NAMESPACE::TensorProto::FLOAT
</code></pre><p>这告诉我们，Cast这个node在进行类型h转换的时候出现了错误，再看看onnx-tensorrt的源码 <code>builtin_op_importers.cpp</code>：</p>
<div class="highlight"><div style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">DEFINE_BUILTIN_OP_IMPORTER(Cast) {
    <span style="color:#998;font-style:italic">// Get input node.
</span><span style="color:#998;font-style:italic"></span>    OnnxAttrs <span style="color:#900;font-weight:bold">attrs</span>(node);
    <span style="color:#000;font-weight:bold">auto</span> cast_dtype <span style="color:#000;font-weight:bold">=</span> attrs.get<span style="color:#000;font-weight:bold">&lt;</span><span style="color:#458;font-weight:bold">int32_t</span><span style="color:#000;font-weight:bold">&gt;</span>(<span style="color:#d14"></span><span style="color:#d14">&#34;</span><span style="color:#d14">to</span><span style="color:#d14">&#34;</span>);
    <span style="color:#000;font-weight:bold">auto</span> <span style="color:#000;font-weight:bold">*</span> tensor_ptr <span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">&amp;</span>convertToTensor(inputs.at(<span style="color:#099">0</span>), ctx);
    <span style="color:#000;font-weight:bold">auto</span> trt_dtype <span style="color:#000;font-weight:bold">=</span> tensor_ptr<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>getType();
    <span style="color:#998;font-style:italic">// TensorRT currently only supports the following conversion: FP16 -&gt; FP32.
</span><span style="color:#998;font-style:italic"></span>    ASSERT(trt_dtype <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> nvinfer1<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>DataType<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kHALF <span style="color:#000;font-weight:bold">&amp;</span><span style="color:#000;font-weight:bold">&amp;</span> cast_dtype <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>ONNX_NAMESPACE<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>TensorProto<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>FLOAT,
          ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kUNSUPPORTED_NODE);
    <span style="color:#998;font-style:italic">// Add the layer.
</span><span style="color:#998;font-style:italic"></span>    nvinfer1<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>IIdentityLayer<span style="color:#000;font-weight:bold">*</span> layer <span style="color:#000;font-weight:bold">=</span> ctx<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>network()<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>addIdentity(inputs.at(<span style="color:#099">0</span>).tensor());
    layer<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>setPrecision(nvinfer1<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>DataType<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kFLOAT);
    RETURN_FIRST_OUTPUT(layer);
}
</code></pre></td></tr></table>
</div>
</div><p>​	这行assertion就是错误的根源，从这个函数来看，它是把FP16转到了FP32, 错误信息并没有告诉我们这个node是将哪个类型转到哪个类型。这个时候咋办？改源码吧，打印一下，它是从哪个类型转到哪个类型。</p>
<p>其实不用改源码，查看一下maskrcnn.onnx里面的每一个Cast大概既知道了：</p>
<pre><code>node: 6622, op_type: Cast | input: ['6659'], output: ['6660']
input: &quot;6659&quot;
output: &quot;6660&quot;
name: &quot;6622&quot;
op_type: &quot;Cast&quot;
attribute {
  name: &quot;to&quot;
  i: 7
  type: INT
}
</code></pre><p>它是将类型转换到INT！但是很显然，这里只支持转到FLOAT32！也即是说，这里的所有的Cast节点似乎都是错误的。因为他们应该转到FLOAT32或者直接去掉不用！</p>
<p>那就继续走这条路吧，解决一下datatype不对的问题。</p>
<p>Cast不支持转到INT64，怎么整？假设这个问题可以解决掉，接下来是第二个问题：</p>
<pre><code>While parsing node number 413 [Resize -&gt; &quot;416&quot;]:
ERROR: /media/fagangjin/wd/permanent/software/source_codes/dl/onnx-tensorrt/builtin_op_importers.cpp:2270 In function importResize:
[8] Assertion failed: scales.is_weights()
</code></pre><p>可以看到，这里的resize是这样的：</p>
<pre><code>node: 415, op_type: Resize | input: ['388', '415'], output: ['416']
input: &quot;388&quot;
input: &quot;415&quot;
output: &quot;416&quot;
name: &quot;415&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}
   
node: 447, op_type: Resize | input: ['420', '447'], output: ['448']
input: &quot;420&quot;
input: &quot;447&quot;
output: &quot;448&quot;
name: &quot;447&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}
   
node: 479, op_type: Resize | input: ['452', '479'], output: ['480']
input: &quot;452&quot;
input: &quot;479&quot;
output: &quot;480&quot;
name: &quot;479&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}
</code></pre><p>可以看到，好像并没有scales 的 weights，resize没有scales参数，这个怎么整。</p>
</li>
<li>
<p>这是第二条线路，第二条线路是先简化模型，然后再convert。</p>
<p>但也遇到了本质上的问题，比如说，这个简化的原理，实际上是根据指定尺寸输入，中间层的一些Shape，Gather, Unsqueeze等都会成为Constant，这些Constant可以被优化掉，不信可以对比一下优化前后的两个图：</p>
<p><img src="../assets/1569487481224.png" alt="1569487481224"></p>
<p>实际上，像Batchnorm这样的层被优化掉了，这个优化来自于官方的优化，optimize，其次类似于Shape、Gather、Unsqueeze这样的层，假如输入尺度确定之后，这些node的参数应该也是被确定的，因此可以直接用来存为Constant，当做常数来用。</p>
<p>但是这一套机制对于动态的输入并没有用。此时这条路应该是走不通的。</p>
</li>
</ol>
<h2 id="mmdetectiononnxtensorrt">mmdetection导入onnx转TensorRT</h2>
<p>上面路子行不通，尝试采用mmdetection导出的onnx，转trt。我们可以比较轻松地把里面的Batchnorm等层去掉，同时对模型进行一下抛光，但是当转到trt的时候，就会遇到各种各样的问题：</p>
<pre><code>node: in: 3020;3029;3030;3028. out: 3031, op_type: Slice | input: ['3020', '3029', '3030', '3028'], output: ['3031']
input: &quot;3020&quot;
input: &quot;3029&quot;
input: &quot;3030&quot;
input: &quot;3028&quot;
output: &quot;3031&quot;
name: &quot;in: 3020;3029;3030;3028. out: 3031&quot;
op_type: &quot;Slice&quot;
</code></pre><p>比如说<code>Slice</code>node会出现错误，而且这个错误是来自于这个：</p>
<pre><code>ASSERT(input_name == &quot;axes&quot; ||  input_name == &quot;steps&quot;, ErrorCode::kUNSUPPORTED_NODE);
</code></pre><p>完全不知所云啊，我们的slice好像并没有这么一个所谓的名字，所以就出现了错误。这就奇怪了，是我们导出的Slice有问题，还是啥问题，为什么onnxruntime里面能够推理，到了onnx-trt里面就不行了呢？</p>
<p>这样把，为了彻底搞明白这个问题，现在需要做一个实验，及调用一切可以用到的资源来进行onnx一个node的运算，这个我叫做元运算(unit onnx), 通过元运算，我们看看这么一个node到底是如何实现前向运算的。</p>
<p><strong>为了解决上诉slice问题，我们修改onnx-trt的源码</strong>:</p>
<p>通过去掉这个assertion，把axes的assign加上，基本上可以解决这个问题了。那么第二个问题来了：</p>
<pre><code>onnx-tensorrt/builtin_op_importers.cpp:2274 In function importResize:
[8] Assertion failed: scales.is_weights()
</code></pre><p>Resize导致的问题，要解决这个问题，深入研究一下先。</p>
<p>首先看一下这个Resize在onnx里面是如何定义：</p>
<blockquote>
<p>Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor. Each dimension value of the output tensor is: output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input &ldquo;sizes&rdquo; is not specified.</p>
</blockquote>
<p>这个op，在opset10和opset11上是不一样的。输入输出不一样，这个就很蛋疼，说实话。</p>
<ul>
<li>
<p>opset10里面的Resize：</p>
<pre><code># Inputs
  X
  scales
# Outputs
  Y
# Attributes
  mode (nearest, linear, bilinear)
</code></pre></li>
<li>
<p>opset11里面的Resize:</p>
<pre><code># Inputs
  X
  roi
  scales
  sizes
# Outputs
  Y
# Attributes
  coordinate_transformation_mode
  cubic_coeff_a
  exclude_outside
  extrapolation_value
  mode
  nearest_mode
</code></pre></li>
</ul>
<p>看到了吗？？？这个Resize在opset10和opset11上操作是不同的。当你把model里面的Resize打印出来之后：</p>
<pre><code>input: &quot;571&quot;
input: &quot;598&quot;
output: &quot;599&quot;
name: &quot;in: 571;598. out: 599&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}

[name: &quot;mode&quot;
s: &quot;nearest&quot;
type: STRING
]
571
598
</code></pre><p>看到了吗？这里的input没有名字，但是第二个，应该scales，如果我没有猜错的话。那么看看onnx-tensorrt里面是怎么暴力处理这个node的：</p>
<div class="highlight"><div style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">    nvinfer1<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>ITensor<span style="color:#000;font-weight:bold">&amp;</span> input <span style="color:#000;font-weight:bold">=</span> convertToTensor(inputs.at(<span style="color:#099">0</span>), ctx);
    <span style="color:#458;font-weight:bold">int</span> input_dims <span style="color:#000;font-weight:bold">=</span> input.getDimensions().nbDims;
    ASSERT(input_dims <span style="color:#000;font-weight:bold">&gt;</span> <span style="color:#099">0</span>, ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kUNSUPPORTED_NODE);

    <span style="color:#998;font-style:italic">// Add resize layer
</span><span style="color:#998;font-style:italic"></span>    nvinfer1<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>IResizeLayer<span style="color:#000;font-weight:bold">*</span> layer <span style="color:#000;font-weight:bold">=</span> ctx<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>network()<span style="color:#000;font-weight:bold">-</span><span style="color:#000;font-weight:bold">&gt;</span>addResize(input);

    <span style="color:#998;font-style:italic">// Retrive and validate scale factors.
</span><span style="color:#998;font-style:italic"></span>    <span style="color:#998;font-style:italic">// Scale factors include batch dimensions as well.
</span><span style="color:#998;font-style:italic"></span>    ASSERT(inputs.size() <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#099">2</span>, ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kINVALID_NODE);
    <span style="color:#000;font-weight:bold">auto</span> scales <span style="color:#000;font-weight:bold">=</span> inputs.at(<span style="color:#099">1</span>);
    <span style="color:#998;font-style:italic">// Support for scales as weights
</span><span style="color:#998;font-style:italic"></span>    <span style="color:#998;font-style:italic">// std::cout &lt;&lt; &#34;uncomment scales.is_weights().\n&#34;;
</span><span style="color:#998;font-style:italic"></span>    ASSERT(scales.is_weights(), ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kUNSUPPORTED_NODE);
    ShapedWeights scales_weights <span style="color:#000;font-weight:bold">=</span> scales.weights();
    ASSERT(scales_weights.shape.nbDims <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#099">1</span>, ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kUNSUPPORTED_NODE);
    ASSERT(scales_weights.count() <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">static_cast</span><span style="color:#000;font-weight:bold">&lt;</span>size_t<span style="color:#000;font-weight:bold">&gt;</span>(input_dims), ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kUNSUPPORTED_NODE);
    ASSERT(scales_weights.type <span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>ONNX_NAMESPACE<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>TensorProto<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>FLOAT, ErrorCode<span style="color:#000;font-weight:bold">:</span><span style="color:#000;font-weight:bold">:</span>kINVALID_NODE);
	.........
</code></pre></td></tr></table>
</div>
</div><p>问题就出在这里了，这里的scales明明就是 <code>inputs.at(1)</code>第二个input没有错啊，但是判断 <code>scales.is_weights()</code>的时候不对了，那么我想知道，这个 <code>is_weights</code>到底是个啥子玩意？？</p>
<p>花了一点时间，开发了一个onnx模型的explore工具：https://github.com/jinfagang/onnxexplorer 磨刀不误砍柴工。接下来需要借助这个工具来解决一下Resize这个问题。简单的来说，解决Resize layer这个<code>is_weights</code> 判断问题。</p>
<p>首先我们用<code>onnxexp</code> 来看一下这个模型里面都有啥：</p>
<pre><code>$ onnxexp bbb.onnx search -t 'Resize'                                          
Exploring on onnx model: bbb.onnx
search node by ID: Resize
input: &quot;542&quot;
input: &quot;569&quot;
output: &quot;570&quot;
name: &quot;in: 542;569. out: 570&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}

input: &quot;571&quot;
input: &quot;598&quot;
output: &quot;599&quot;
name: &quot;in: 571;598. out: 599&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}

input: &quot;600&quot;
input: &quot;627&quot;
output: &quot;628&quot;
name: &quot;in: 600;627. out: 628&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}

listed all 3 Resize nodes in detail.
</code></pre><p>搜索了一下，Resize的op也就三个，似乎不是什么大问题啊，这里对比一下yolov3.onnx里面的Resize node看看：</p>
<pre><code>$ onnxexp yolov3.onnx search -t 'Resize'
Exploring on onnx model: yolov3.onnx
search node by ID: Resize
input: &quot;model_1/leaky_re_lu_59/LeakyRelu:0&quot;
input: &quot;Resize_scales&quot;
output: &quot;model_1/leaky_re_lu_59/LeakyRelu:0_permuted_upsampled&quot;
name: &quot;Resize1&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}
doc_string: &quot;&quot;
domain: &quot;&quot;

input: &quot;model_1/leaky_re_lu_66/LeakyRelu:0&quot;
input: &quot;Resize_scales&quot;
output: &quot;model_1/leaky_re_lu_66/LeakyRelu:0_permuted_upsampled&quot;
name: &quot;Resize&quot;
op_type: &quot;Resize&quot;
attribute {
  name: &quot;mode&quot;
  s: &quot;nearest&quot;
  type: STRING
}
doc_string: &quot;&quot;
domain: &quot;&quot;

listed all 2 Resize nodes in detail.
</code></pre><p>可以看到，它这个Resize的input比较正常一些，<code>Resize_scales</code>是输入的scales，我们看看这个scales到底是个啥？主要看看是不是weights。</p>
<p>经过一番debug之后，发现这个Resize的op似乎有点不太正常啊，并没有这个scales的输入，那咋办呢。其实这个scales的来源是有的，来自于concat的输出。</p>
<h2 id="heading">总结</h2>
<p>最后总结一下，通过onnx转到maskrcnn存在以下问题：</p>
<ul>
<li>一些支持的op比如Resize，并非真正的支持，Resize如果scales来自另外一个node的输出将不支持，只支持写死的scales参数；</li>
<li>一些层不支持如RoIAlign，这个层需要写Plugin去支持， 另外一些不支持的包括： <code>NonMaxSuppression, Equal, ReverseSequence(mmdet version only), NonZero，Scatter（fb version only)，  </code>；</li>
</ul>
<p>解决办法和难点：</p>
<ul>
<li>一些不支持的op如ROIAlign可以通过在onnx-tensorrt里面自己写importer来支持导入，然后根据inputs和outputs来编写逻辑，但对于一些已经被支持的层但无法处理特殊情况的op，无法debug到底正确操作应该是啥样的，比如onnx-tensorrt官方里面将Resize parse的时候第二个inputs parse为weights，这通常情况下是initializers，但模型里面来自于上一个node的输出，意味着这个层无法再转engine的过程中被构建。Slice层onnx-tensorrt在处理的时候会将一些位置参数按照标准格式来处理，但对于一些trace的模型一些参数的名称并非严格按照标准来的，通过修改onnx-tensorrt源码可以给它修改。</li>
<li>至少需要重写Resize层，增加ROIAlign，NMS，Nonzeros，Equal等层，工作量还是比较大。</li>
</ul>

        </div>

        
<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://jintian93.github.io">金天</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://jintian93.github.io/post/2019_09_26_10_maskrcnn-benchmark%E8%BD%AConnx%E5%86%8D%E8%BD%ACTensorRT%E5%AE%9E%E5%BD%95/">https://jintian93.github.io/post/2019_09_26_10_maskrcnn-benchmark%E8%BD%AConnx%E5%86%8D%E8%BD%ACTensorRT%E5%AE%9E%E5%BD%95/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/post/2019_09_19_15_pytorch%E9%87%8C%E9%9D%A2%E7%9A%84torch.gather%E6%93%8D%E4%BD%9C/">pytorch里面的torch.gather操作</a></li>
        
        <li><a href="/post/2019_09_12_11_FOTS%E5%92%8CROIRotate%E4%BB%A5%E5%8F%8A%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/">FOTS和ROIRotate以及仿射变换</a></li>
        
        <li><a href="/post/2019_09_11_18_onnx-tensorrt%E5%AE%9E%E7%8E%B0%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8Bplugin/">onnx-tensorrt实现添加自己的模型plugin</a></li>
        
        <li><a href="/post/2019_08_20_20_%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91Apollo_Cyber%E7%B3%BB%E7%BB%9F/">本地编译Apollo Cyber系统</a></li>
        
        <li><a href="/post/2019_08_06_16_cron%E5%88%9B%E5%BB%BA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/">cron创建定时任务</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            没有标签
            
        </div>
    </article>
    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "jintian93/coment-for-blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://jintian93.github.io/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://jintian93.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_30_16_DETR%E4%BD%BF%E7%94%A8Transformer%E5%81%9A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%BF%8E%E6%9D%A5%E4%BA%860.2%E7%89%88%E6%9C%AC%E7%9A%84%E5%8F%91%E5%B8%83/" title="DETR使用Transformer做目标检测的模型迎来了0.2版本的发布">DETR使用Transformer做目标检测的模型迎来了0.2版本的发布</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_23_15_%E8%81%8A%E4%B8%80%E8%81%8A%E4%BB%8A%E5%B9%B4%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%E9%A2%86%E5%9F%9F%E7%9A%84%E8%BF%9B%E5%B1%95%E5%92%8C%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B/" title="聊一聊今年实例分割领域的进展和未来展望">聊一聊今年实例分割领域的进展和未来展望</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_19_11_YoloV5%E7%9A%84TensorRT%E5%8A%A0%E9%80%9F%E5%AE%9E%E7%8E%B049FPSmAP40&#43;/" title="YoloV5的TensorRT加速实现49FPS，mAP40&#43;!">YoloV5的TensorRT加速实现49FPS，mAP40&#43;!</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_11_17_%E4%BD%BF%E7%94%A8mmdetection2.0%E5%AE%9E%E7%8E%B0SOLOV2-%E5%85%A8%E6%96%B0%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%E6%A1%86%E6%9E%B6/" title="使用mmdetection2.0实现SOLOV2-全新的实例分割框架">使用mmdetection2.0实现SOLOV2-全新的实例分割框架</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_10_16_%E9%87%8D%E7%A3%85%E8%85%BE%E8%AE%AF%E4%BC%98%E5%9B%BE%E5%BC%80%E6%BA%90%E6%9C%80%E6%96%B0%E5%89%8D%E7%AB%AF%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6TNN/" title="重磅！腾讯优图开源最新前端推理框架TNN！">重磅！腾讯优图开源最新前端推理框架TNN！</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_09_12_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0CUDA%E7%BC%96%E7%A8%8B%E5%B9%B2%E8%B4%A7-kernel%E7%9A%84%E7%BC%96%E5%86%99%E5%92%8C%E8%B0%83%E7%94%A8/" title="深度学习CUDA编程干货-kernel的编写和调用">深度学习CUDA编程干货-kernel的编写和调用</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_06_03_11_%E5%B9%B2%E8%B4%A7%E4%B8%80%E6%96%87%E6%8E%8C%E6%8F%A1Protobuf%E6%89%80%E6%9C%89%E8%AF%AD%E8%A8%80%E6%89%80%E6%9C%89%E7%94%A8%E6%B3%95%E5%BF%AB%E6%94%B6%E8%97%8F/" title="干货！一文掌握Protobuf所有语言所有用法，快收藏！">干货！一文掌握Protobuf所有语言所有用法，快收藏！</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_05_30_15_PolyYolo%E5%BC%80%E6%BA%90Yolo%E4%B9%9F%E8%83%BD%E5%81%9A%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%E6%A3%80%E6%B5%8BmAP%E6%8F%90%E5%8D%8740/" title="PolyYolo开源！Yolo也能做实例分割，检测mAP提升40%！">PolyYolo开源！Yolo也能做实例分割，检测mAP提升40%！</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_05_30_10_%E9%9C%87%E6%83%8AYoloV4%E8%BF%98%E6%B2%A1%E6%9C%89%E9%80%80%E7%83%ADYoloV5%E5%B7%B2%E7%BB%8F%E5%8F%91%E5%B8%83/" title="震惊！YoloV4还没有退热，YoloV5已经发布！">震惊！YoloV4还没有退热，YoloV5已经发布！</a>
    </li>
    
    <li>
        <a href="https://jintian93.github.io/post/2020_05_28_14_DETR%E8%AF%A6%E8%A7%A3NLP%E9%87%8C%E9%9D%A2%E7%9A%84Transformer%E4%B9%9F%E8%83%BD%E5%81%9A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" title="DETR详解:NLP里面的Transformer也能做目标检测？">DETR详解:NLP里面的Transformer也能做目标检测？</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="http://manaai.cn" title="【2020】中秋特惠，神力平台终身会员优惠85折！立即开通" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1_rYHo7P2gK0jSZPxXXacQpXa-690-388.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="http://manaai.cn" title="助力产业智慧升级，云服务器首年88元起，更有千元代金券礼包免费领！" target="_blank" style="color:red">
                
                    <img src="https://upload-dianshi-1255598498.file.myqcloud.com/345-7c71532bd4935fbdd9a67c1a71e577b1767b805c.200%E7%89%88%E6%9C%ACB.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="http://manaai.cn" title="【渠道专享低折扣】11月特惠 限时2折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1hblJl7Y2gK0jSZFgXXc5OFXa-750-400.jpg">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">分类</h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">标签</h3>
<div class="tagcloud">
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="http://manaai.cn" title="神力AI平台">神力AI平台</a>
        </li>
        
        <li>
            <a target="_blank" href="http://zhuanlan.zhihu.com/ai-man" title="【知乎专栏】人工智能从入门到逆天杀神">Android Gradle权威指南</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://jintian93.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
    <footer id="footer">
    <div class="container">
        &copy; 2020 <a href="https://jintian93.github.io">金天的个人博客 By 金天</a>.
        Powered by <a rel="nofollow noreferer noopener" href="https://gohugo.io" target="_blank">Hugo</a>.
        <a href="https://www.flysnow.org/" target="_blank">Theme</a> based on <a href="https://github.com/flysnow-org/maupassant-hugo" target="_blank">maupassant</a>.
        
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>


<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>

</body>

</html>